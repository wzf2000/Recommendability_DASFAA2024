# dataset
dataset: DuRecDial
language: zh
tokenize: gpt2
# dataloader
context_truncate: 512
response_truncate: 30
item_truncate: 100
scale: 1
# model
model: ConvGPT2
# optim
loss: BCEWithLogitsLoss
policy:
  epoch: 5
  batch_size: 2
  weight_decay: 0.01
  optimizer:
    name: AdamW
    lr: !!float 1e-5
  early_stop: true
  stop_mode: max
  impatience: 3
